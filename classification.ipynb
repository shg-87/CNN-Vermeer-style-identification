{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb49a50",
   "metadata": {},
   "source": [
    "# Vermeer style identification\n",
    "\n",
    "# Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a09140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13811593",
   "metadata": {},
   "source": [
    "In a previous notebook we have extracted features from the paintings by Johannes Vermeer and performed some visualization techniques of the feature vectors obtained. Here we will repeat the process for the ``no vermeer`` class, corresponding to paintings of other Dutch artists of the same period, and use the whole set of features train a classifier to distinguish between Vermeer and other artists. Concretely, we will focus on the features extracted by ResNet50, which showed a better feature extraction capability in the previous notebook. Finally we will test the model on a set of paintings that includes \"Girl with a flute\", the painting whose provenance was questioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8903c6",
   "metadata": {},
   "source": [
    "## Preprocessing of paintings by other artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c5504b",
   "metadata": {},
   "source": [
    "We follow the same steps as in the previous notebook for preprocessing our set of images of paintings by other artists from the Dutch Baroque: first cropping the images into squares and the resizing to match the usual input format for CNNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb125eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def sweep_square_and_crop(folder_path, output_folder, step_size=200):\n",
    "    \"\"\"\n",
    "    Sweep a square over each image and crop it to produce multiple square images.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): Path to the folder containing images.\n",
    "    output_folder (str): Path to the folder where the squared images will be saved.\n",
    "    step_size (int): The step size for sweeping the square over the image. Fixed to 200 steps by default.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create the output folder\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(image_path) as img:\n",
    "                # Determine the size of the square (minimum of width and height of the image)\n",
    "                square_size = min(img.size)\n",
    "\n",
    "                for x in range(0, img.width - square_size + 1, step_size):\n",
    "                    for y in range(0, img.height - square_size + 1, step_size):\n",
    "                        # Define the crop box\n",
    "                        box = (x, y, x + square_size, y + square_size)\n",
    "                        cropped_image = img.crop(box)\n",
    "\n",
    "                        # Construct the output filename\n",
    "                        output_filename = f\"{os.path.splitext(filename)[0]}_{x}_{y}.png\"\n",
    "                        # Save the cropped image\n",
    "                        cropped_image.save(os.path.join(output_folder, output_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77cf8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_square_and_crop('./no vermeer/details', './no vermeer/cropped', step_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61265a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132366ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sergi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def resize(input_folder, output_folder, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize images to the given size and save them as\n",
    "    numpy arrays in a separate folder.\n",
    "\n",
    "    Args:\n",
    "    - input_folder (str): Folder containing the original images.\n",
    "    - output_folder (str): Folder where numpy arrays of processed images will be saved.\n",
    "    - size (tuple): New size of the images. Default is (224, 224).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    # Resize images\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = load_img(img_path, target_size=size)\n",
    "            img_array = img_to_array(img)\n",
    "\n",
    "            # Save the numpy array\n",
    "            array_filename = os.path.splitext(filename)[0] + '.npy'\n",
    "            save_path = os.path.join(output_folder, array_filename)\n",
    "            np.save(save_path, img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7e6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = './no vermeer/cropped'\n",
    "destination_folder = './no vermeer/preprocessed'\n",
    "resize(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b2a15",
   "metadata": {},
   "source": [
    "The resized images have been stored as ``.npy`` files in te folder ``no vermeer\\preprocessed``. Note that we have a rather balanced dataset (758 Vermeer versus 685 no Vermeer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d2c5ce",
   "metadata": {},
   "source": [
    "## Extracting features and creating labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c0b1e",
   "metadata": {},
   "source": [
    "In this section we will extract ResNet50 features for each ``.npy`` image in the ``vermeer\\preprocessed`` and ``no vermeer\\preprocessed`` folders and creates labels for each class. Note that we will have to use the function ``preprocess_input`` in Keras in order to the image data to match the format and distribution expected by ResNet5t.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a7a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sergi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sergi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sergi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top layer (for feature extraction)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# This function loads the images in \"folder\"\n",
    "def load_npy_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = np.load(img_path)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# This function extracts features in the numpy array of images \"images\"\n",
    "def extract_features(images):\n",
    "    # Preparing the image data to match the format and distribution expected by ResNet50\n",
    "    images = preprocess_input(images)\n",
    "    # Extract features\n",
    "    features = feature_extractor.predict(images, batch_size=16)\n",
    "    return features\n",
    "\n",
    "# Load images in our directories\n",
    "vermeer_images = load_npy_images('./vermeer/preprocessed')\n",
    "no_vermeer_images = load_npy_images('./no vermeer/preprocessed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2c5ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 78s 2s/step\n",
      "43/43 [==============================] - 67s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "vermeer_features = extract_features(vermeer_images)\n",
    "no_vermeer_features = extract_features(no_vermeer_images)\n",
    "\n",
    "# Create labels (1 for Vermeer, 0 for no Vermeer)\n",
    "vermeer_labels = np.ones(len(vermeer_features))\n",
    "no_vermeer_labels = np.zeros(len(no_vermeer_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af32031a",
   "metadata": {},
   "source": [
    "We shall combine the features and labels and split the dataset into a train and validation set. The former will serve us to test the metrics of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba358c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features and labels\n",
    "features = np.concatenate((vermeer_features, no_vermeer_features), axis=0)\n",
    "labels = np.concatenate((vermeer_labels, no_vermeer_labels), axis=0)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb2498",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b559cc",
   "metadata": {},
   "source": [
    "Now we have our correctly preprocessed train and validation sets it is time to perform classification. We will use a Support Vector Machine (SVM) as our classifier- SVMs are known for their effectiveness in dealing with high-dimensional spaces, making them suitable for being used in complex feature sets derived from artworks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2edfcdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM classifier\n",
    "svm_clf = make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the validation set\n",
    "y_pred = svm_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e9318",
   "metadata": {},
   "source": [
    "Note we are using SVC with ``probability=True``: the SVM classifier is equipped to output probabilities for each class. These probabilities are derived using an additional logistic regression on the decision values returned by the SVM, fitted via a process called Platt scaling during the fit method. The classification into 0 or 1 happens based on these probabilities: the class with the highest probability is chosen as the prediction for each sample. In our case, if the probability of the positive class is greater than or equal to 0.5, the sample is classified as 1. Otherwise, it is classified as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d69df8",
   "metadata": {},
   "source": [
    "We shall now evaluate the model in our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff57a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9689\n",
      "Precision: 0.9618\n",
      "Recall: 0.9805\n",
      "F1 Score: 0.9711\n",
      "ROC AUC Score: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;svc&#x27;, SVC(probability=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;svc&#x27;, SVC(probability=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(probability=True))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# For ROC AUC score, we need the probability estimates of the positive class\n",
    "y_proba = svm_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_proba)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "svm_clf = make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "svm_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c6598",
   "metadata": {},
   "source": [
    "The results indicate that our model performs quite well on the validation set. Let us recall the meaning of these metrics:\n",
    "\n",
    "Accuracy (0.9689): the classifier correctly predicts the class of 96.89% of the samples, indicating overall good performance across both classes.\n",
    "\n",
    "Precision (0.9618): when the classifier predicts a sample as belonging to the positive class, it is correct 96.18% of the time. High precision indicates a low false positive rate.\n",
    "\n",
    "Recall (0.9805): The classifier correctly identifies 98.05% of all actual positive samples. High recall indicates a low false negative rate.\n",
    "\n",
    "F1 Score (0.9711): The F1 score is the harmonic mean of precision and recall, providing a single metric to measure the balance between them. The F1 score close to 1, suggesting that the classifier achieves an excellent balance between precision and recall.\n",
    "\n",
    "ROC AUC Score (0.9971): the Area Under the Receiver Operating Characteristic Curve (ROC AUC) measures the classifier's ability to distinguish between the classes across all possible thresholds. A score close to 1 indicates an excellent ability to differentiate between positive and negative classes. This suggests that the classifier is highly reliable in its predictions.\n",
    "\n",
    "As a note, the precision being slightly lower than recall (but still high) suggests that there are some false positives, but their number is very low compared to true positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114f46a",
   "metadata": {},
   "source": [
    "## Predictions on a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f648f",
   "metadata": {},
   "source": [
    "We shall now address the original question: what does the model say about the provenance of \"Girl with a flute\"?\n",
    "\n",
    "We shall consider a test set of paintings and some patches thereof, including \"Girl with a flute\". For Vermeer paintings, we will use pictures obtained from a different source than the one used for training the model. For paintings by other artists, we will simply use other artworks not used in our previous dataset. The images have been stored in the folder ``./test``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f52b5a9",
   "metadata": {},
   "source": [
    "As usual, we need to correctly process these images. The processed pictures have been stored in ``./test/preprocessed``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = './test/cropped'\n",
    "destination_folder = './test/preprocessed'\n",
    "resize(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa63cab",
   "metadata": {},
   "source": [
    "We now create a function that extracts features from the images in our test folder and outputs the probability of being a Vermeer computed by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "444760fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 5s 1s/step\n",
      "Image 1: Predicted probability of being a Vermeer painting: 0.025572119523263524\n",
      "Image 2: Predicted probability of being a Vermeer painting: 0.07385237094306933\n",
      "Image 3: Predicted probability of being a Vermeer painting: 0.09684409436667323\n",
      "Image 4: Predicted probability of being a Vermeer painting: 0.0019061251631808326\n",
      "Image 5: Predicted probability of being a Vermeer painting: 0.010464657595303363\n",
      "Image 6: Predicted probability of being a Vermeer painting: 0.9961084864787438\n",
      "Image 7: Predicted probability of being a Vermeer painting: 0.986035101824995\n",
      "Image 8: Predicted probability of being a Vermeer painting: 0.9204058822877744\n",
      "Image 9: Predicted probability of being a Vermeer painting: 0.4509658444854587\n",
      "Image 10: Predicted probability of being a Vermeer painting: 0.9291889975668969\n",
      "Image 11: Predicted probability of being a Vermeer painting: 0.5197314690690261\n",
      "Image 12: Predicted probability of being a Vermeer painting: 0.9861043531226897\n",
      "Image 13: Predicted probability of being a Vermeer painting: 0.023057501945172712\n",
      "Image 14: Predicted probability of being a Vermeer painting: 0.9932881694796117\n",
      "Image 15: Predicted probability of being a Vermeer painting: 0.04809630250271349\n",
      "Image 16: Predicted probability of being a Vermeer painting: 0.9999858540083026\n",
      "Image 17: Predicted probability of being a Vermeer painting: 0.039234136149782474\n",
      "Image 18: Predicted probability of being a Vermeer painting: 0.024127662312274242\n",
      "Image 19: Predicted probability of being a Vermeer painting: 0.2777794858394903\n",
      "Image 20: Predicted probability of being a Vermeer painting: 0.5368975807103314\n",
      "Image 21: Predicted probability of being a Vermeer painting: 0.10181916427575831\n",
      "Image 22: Predicted probability of being a Vermeer painting: 0.11315536167627449\n",
      "Image 23: Predicted probability of being a Vermeer painting: 0.9899966290770005\n",
      "Image 24: Predicted probability of being a Vermeer painting: 0.980802552546543\n",
      "Image 25: Predicted probability of being a Vermeer painting: 0.9949446558776563\n",
      "Image 26: Predicted probability of being a Vermeer painting: 0.9904661169778927\n",
      "Image 27: Predicted probability of being a Vermeer painting: 0.9974100471897637\n",
      "Image 28: Predicted probability of being a Vermeer painting: 0.7276033766236565\n",
      "Image 29: Predicted probability of being a Vermeer painting: 0.9439589474517146\n",
      "Image 30: Predicted probability of being a Vermeer painting: 0.8686192290075873\n",
      "Image 31: Predicted probability of being a Vermeer painting: 0.961221369683122\n",
      "Image 32: Predicted probability of being a Vermeer painting: 0.852113101770042\n",
      "Image 33: Predicted probability of being a Vermeer painting: 0.9865165826457\n",
      "Image 34: Predicted probability of being a Vermeer painting: 0.9727936610162621\n"
     ]
    }
   ],
   "source": [
    "def predict_vermeer_probabilities_svm(image_folder, svm_clf):\n",
    "    \"\"\"Predict the probability of .npy images being Vermeer paintings using the trained SVM classifier.\"\"\"\n",
    "    # Load .npy images from the specified folder\n",
    "    images = load_npy_images(image_folder)  # Reuse the function defined earlier\n",
    "    \n",
    "    # Extract features using the pre-trained ResNet\n",
    "    features = extract_features(images)  # Reuse the function defined earlier\n",
    "    \n",
    "    # Predict probabilities using the trained SVM classifier\n",
    "    probabilities = svm_clf.predict_proba(features)[:, 1]  # Get probability for the positive class (Vermeer)\n",
    "    \n",
    "    # Print the predicted probabilities for each image\n",
    "    for idx, prob in enumerate(probabilities):\n",
    "        print(f\"Image {idx+1}: Predicted probability of being a Vermeer painting: {prob}\")\n",
    "\n",
    "# Specify the folder containing .npy test images\n",
    "test_image_folder = './test/preprocessed'\n",
    "\n",
    "# Predict and print the probabilities\n",
    "predict_vermeer_probabilities_svm(test_image_folder, svm_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a715310",
   "metadata": {},
   "source": [
    "Let us analyze the meaning of these results. The first five paintings correspond to paintings by other artists, so the classifier is doing its job well. Image 6 is \"Girl with a flute\", and Image 7 to Image 11 are different patches of the painting.  While the whole picture is classified as a Vermeer, the output probability of the different zoomed-in patches differ. Crucially, for patches involving the face, hand and central part of the jacket of the portrayed character, the classifier outputs a high probability of being a Vermeer, whereas for peripheric details the probability is considerably lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7af9c",
   "metadata": {},
   "source": [
    "Details with high probability of belonging to Vermeer class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b2f2eb",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/flute1.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a6874",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/flute2.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa907e",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/flute6.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656350e",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/flute8.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f000d",
   "metadata": {},
   "source": [
    "Details with low probability of belonging to Vermer class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb5163",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/flute5.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66661e51",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/flute7.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04457a",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/flute9.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b608ed",
   "metadata": {},
   "source": [
    "Images 14, 16 and 20 are forgeries from the 20th century, in the style of Vermeer. Images 15, 17-19 and 21-22 are their respective zoomed-in details. While for the whole images the classifier outputs a high probability, zoomed-in patches result in a low probability of being a Vermeer. This suggests that our model recognizes a similar style in forgeries as a whole but is able to tell them apart from originals when focusing on details. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf7b71",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/forgery1.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc7d2e",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/forgery1-1.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7e18f",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/forgery2.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb19c4c",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/forgery2-1.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b25f5",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/forgery2-2.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242fb23",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/forgery3.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2287e",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/forgery3-1.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598cc6bb",
   "metadata": {},
   "source": [
    "<img src=\"./test/cropped/forgery3-3.png\" width=\"400\" height=\"300\" alt=\"description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46200e92",
   "metadata": {},
   "source": [
    "Finally, the rest of the pictures are all by Vermeer, either complete pictures or details. We observe that the model outputs a very high probability for all of them. Recall that these pictures have been taken from a different source, so they are in practice different instances from those in the original dataset used for training and validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695fc5e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52a2ee",
   "metadata": {},
   "source": [
    "Our results suggests that our model:\n",
    "    \n",
    "1. indeed tells apart paintings by Vermeer from other painters of the same school but with different style, \n",
    "2. for imitators, the whole painting passes the test but zommed-in details do not.\n",
    "\n",
    "The situation is not so clear for \"Girl with a flute\": while the whole painting is indeed classified as a Vermeer, several zoomed-in patches are not. The fact that the positive patches are the most relevant of the artwork (face, hand, central piece of the character's jacket) while the negative ones correspon to peripheric details (hat, wristle details of the jacket, chair in the background) strengthen the hypothesis that the painting belongs to Vermeer's studio, with Vermeer in charge of the main aspects of the portrait and some pupil taking care of the rest of the painting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e40a1",
   "metadata": {},
   "source": [
    "It would be interesting to perform further studies that either refine our current model or consider a different model for comparison, and also refining our feature extraction scheme. For instance, we can try a dense layer as a classifier instead of a SVM. Adding to our current model the texture and edge detection features that were described in the previous notebook does not produce significant changes in the output, but we could certainly consider  extracting features with a less sophisticated custom CNN and complement them with texture and edge information, and compare the performance of classifiers. Other nuances in the feature extraction process include taking care of lighting: given the fact that the Vermeer paintings (including \"Girl with a flute\" were taken under similar lightning conditions for the 2023 exhibition at Reijksmuseum, we could introduce brightness and contrast variations in that set to prevent bias to particular lightning conditions. Finally, we can also improve the dataset we have used by further data augmentation, taking a larger number of well-selected zoomed-in patches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa946dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
